{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dir:  d:\\我的\\大学\\3暑\\创新实践\\repo\\Nonlinear-Erasure-Code\\src\\NewMethod\n",
      "changed dir:  d:\\我的\\大学\\3暑\\创新实践\\repo\\Nonlinear-Erasure-Code\\src\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"original dir: \", os.getcwd())\n",
    "\n",
    "if os.getcwd().endswith(\"NewMethod\"):\n",
    "    new_path = \"../\"\n",
    "    os.chdir(new_path)\n",
    "    print(\"changed dir: \", os.getcwd())\n",
    "    \n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "TASK_CONFIG = {\n",
    "    \"TASK\": \"MNIST\",  # ARG\n",
    "    \"DATE\": datetime.datetime.now().strftime(\"%Y_%m_%d\"),\n",
    "    \"MODEL\": \"LeNet5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前任务为 MNIST\n",
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置数据转换\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# 设置数据集（训练集与测试集合）\n",
    "\n",
    "\"\"\"\n",
    "MNIST:\n",
    "image: (1, 28, 28), label: (0-9)\n",
    "\n",
    "FashionMNIST:\n",
    "image: (1, 28, 28), label: (0-9)\n",
    "\n",
    "CIFAR10:\n",
    "image: (3, 32, 32), label: (0-9)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"当前任务为 {TASK_CONFIG['TASK']}\")\n",
    "\n",
    "# ARG\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(\n",
    "#     root=\"./data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_dataset = datasets.FashionMNIST(\n",
    "#     root=\"./data\", train=False, download=True, transform=transform\n",
    "# )\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Data is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置部分参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 4\n",
      "R: 2\n",
      "N: 6\n",
      "data_shape: (1, 28, 28)\n",
      "num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "# ARG\n",
    "K = 4\n",
    "R = 2\n",
    "N = K + R\n",
    "original_data_shape = tuple(train_dataset[0][0].shape)\n",
    "num_classes = 10\n",
    "print(f\"K: {K}\")\n",
    "print(f\"R: {R}\")\n",
    "print(f\"N: {N}\")\n",
    "print(f\"data_shape: {original_data_shape}\")\n",
    "print(f\"num_classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from base_model.MyModel1 import MyModel1\n",
    "from base_model.LeNet5 import LeNet5\n",
    "\n",
    "# 引入 base model, 该model将在后续全部过程中使用\n",
    "# ResNet\n",
    "assert TASK_CONFIG[\"MODEL\"] == \"LeNet5\"\n",
    "model = LeNet5(input_dim=original_data_shape, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_path: ./base_model/LeNet5/MNIST/model.pth\n",
      "Model is ready!\n"
     ]
    }
   ],
   "source": [
    "# 读取模型\n",
    "base_model_path = (\n",
    "    f\"./base_model/{TASK_CONFIG['MODEL']}/{TASK_CONFIG['TASK']}/model.pth\"\n",
    ")\n",
    "print(f\"base_model_path: {base_model_path}\")\n",
    "\n",
    "model.load_state_dict(torch.load(base_model_path, map_location=device))\n",
    "conv_segment = model.get_conv_segment()\n",
    "fc_segment = model.get_fc_segment()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 base model 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集-> 总量: 60000, 正确数量: 59612, 准确率: 99.35333333333334%\n",
      "测试集-> 总量: 10000, 正确数量: 9891, 准确率: 98.91%\n"
     ]
    }
   ],
   "source": [
    "# 测试循环\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 在评估过程中不计算梯度\n",
    "    for data, target in train_loader:\n",
    "        # 将数据移动到设备上\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"训练集-> 总量: {total}, 正确数量: {correct}, 准确率: {100 * correct / total}%\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 在评估过程中不计算梯度\n",
    "    for data, target in test_loader:\n",
    "        # 将数据移动到设备上\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"测试集-> 总量: {total}, 正确数量: {correct}, 准确率: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 model 和 conv_segment, fc_segment 的输出是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5826,  0.0391,  4.3020,  1.7877, -2.2489, -1.4453, -0.9584, -0.2722,\n",
      "          1.9820, -3.2926]], device='cuda:0')\n",
      "tensor([[ 0.5826,  0.0391,  4.3020,  1.7877, -2.2489, -1.4453, -0.9584, -0.2722,\n",
      "          1.9820, -3.2926]], device='cuda:0')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, *original_data_shape).to(device)\n",
    "model.to(device)\n",
    "y = model(x)\n",
    "print(y.data)\n",
    "\n",
    "z = conv_segment(x)\n",
    "z = z.flatten(1)\n",
    "z = fc_segment(z)\n",
    "print(z.data)\n",
    "print(torch.allclose(y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置另一部分参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_output_shape: (16, 4, 4)\n",
      "split_conv_output_shape: (16, 4, 1)\n",
      "split_data_range: [(1, 28, 0, 19), (1, 28, 4, 23), (1, 28, 8, 27), (1, 28, 12, 28)]\n",
      "split_conv_output_data_shape from split_data_shape: [(1, 16, 4, 1), (1, 16, 4, 1), (1, 16, 4, 1), (1, 16, 4, 1)]\n",
      "split_data_shapes: [(1, 28, 19), (1, 28, 19), (1, 28, 19), (1, 28, 16)]\n",
      "choose the first one as the split_data_shape: (1, 28, 19)\n"
     ]
    }
   ],
   "source": [
    "from util.util import cal_input_shape\n",
    "\n",
    "\n",
    "conv_output_shape = model.calculate_conv_output(input_dim=original_data_shape)\n",
    "print(f\"conv_output_shape: {conv_output_shape}\")\n",
    "assert conv_output_shape[2] % K == 0\n",
    "\n",
    "split_conv_output_shape = (\n",
    "    conv_output_shape[0],\n",
    "    conv_output_shape[1],\n",
    "    conv_output_shape[2] // K,\n",
    ")\n",
    "print(f\"split_conv_output_shape: {split_conv_output_shape}\")\n",
    "\n",
    "conv_segment.to('cpu')\n",
    "split_data_range = cal_input_shape(\n",
    "    model=conv_segment,\n",
    "    original_input_shape=original_data_shape,\n",
    "    original_output_shape=conv_output_shape,\n",
    "    split_num=K,\n",
    ")\n",
    "print(f\"split_data_range: {split_data_range}\")\n",
    "\n",
    "# print(conv_segment)\n",
    "print(\n",
    "    f\"split_conv_output_data_shape from split_data_shape: {[tuple(conv_segment(torch.randn(1, _[0], _[1], _[3] - _[2])).shape) for _ in split_data_range]}\"\n",
    ")\n",
    "\n",
    "split_data_shapes = [\n",
    "    (\n",
    "        _[0],\n",
    "        _[1],\n",
    "        _[3] - _[2],\n",
    "    )\n",
    "    for _ in split_data_range\n",
    "]\n",
    "print(f\"split_data_shapes: {split_data_shapes}\")\n",
    "\n",
    "split_data_shape = split_data_shapes[0]\n",
    "print(f\"choose the first one as the split_data_shape: {split_data_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证分割后的输入，能够恰好恢复出原始输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape: torch.Size([1, 16, 4, 4])\n",
      "y_split.shape: [(1, 16, 4, 1), (1, 16, 4, 1), (1, 16, 4, 1), (1, 16, 4, 1)]\n",
      "y_hat.shape: torch.Size([1, 16, 4, 4])\n",
      "y和y_hat是否相等: True\n",
      "y和y_hat是否相等: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, *original_data_shape).to(device)\n",
    "conv_segment.to(device)\n",
    "y = conv_segment(x)\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "\n",
    "x_split = [x[:, :, :, _[2]:_[3]] for _ in split_data_range]\n",
    "y_split = [conv_segment(_x) for _x in x_split]\n",
    "print(f\"y_split.shape: {[tuple(_y.shape) for _y in y_split]}\")\n",
    "\n",
    "y_hat = torch.cat(y_split, dim=3)\n",
    "print(f\"y_hat.shape: {y_hat.shape}\")\n",
    "\n",
    "# |A-B| <= atol + rtol * |B|\n",
    "print(f\"y和y_hat是否相等: {torch.allclose(y_hat, y, rtol=1e-08, atol=1e-05)}\")\n",
    "\n",
    "diff = torch.abs(y_hat - y)\n",
    "epsilon = 0.0001\n",
    "print(f\"y和y_hat是否相等: {torch.all(diff <= epsilon)}\")\n",
    "# print(torch.allclose(y_split[0], y[:, :, :, 0:5]))\n",
    "# print(torch.allclose(y_split[1], y[:, :, :, 5:10]))\n",
    "# print(torch.allclose(y_split[2], y[:, :, :, 10:15]))\n",
    "# print(torch.allclose(y_split[3], y[:, :, :, 15:20]))\n",
    "\n",
    "# print(y[0][0][0] == y_hat[0][0][0])\n",
    "# print(y[0][0][0])\n",
    "# print(y_hat[0][0][0])\n",
    "# y = x\n",
    "# y_split = x_split\n",
    "# for layer in conv_segment:\n",
    "#     print(layer)\n",
    "#     y = layer(y)\n",
    "#     y_split = [layer(_y) for _y in y_split]\n",
    "#     print(f\"y.shape: {y.shape}\")\n",
    "#     print(f\"y_split.shape: {[tuple(_.shape) for _ in y_split]}\")\n",
    "#     print(y[0][0][0])\n",
    "#     print(y_split[0][0][0][0])\n",
    "#     print(y_split[1][0][0][0])\n",
    "#     print(y_split[2][0][0][0])\n",
    "#     print(y_split[3][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_data_shape: (1, 28, 19)\n",
      "split_conv_output_shape: (16, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "from encoder.mlp_encoder import MLPEncoder\n",
    "from encoder.conv_encoder import CatChannelConvEncoder, CatBatchSizeConvEncoder\n",
    "from decoder.mlp_decoder import MLPDecoder\n",
    "from decoder.conv_decoder import CatChannelConvDecoder, CatBatchSizeConvDecoder\n",
    "from decoder.sparse_mlp_decoder import SparseMLPDecoder\n",
    "\n",
    "print(f\"split_data_shape: {split_data_shape}\")\n",
    "print(f\"split_conv_output_shape: {split_conv_output_shape}\")\n",
    "\n",
    "# ARG\n",
    "\n",
    "# encoder = MLPEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "# decoder = MLPDecoder(num_in=N, num_out=K, in_dim=split_conv_output_shape)\n",
    "\n",
    "encoder = CatChannelConvEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "# decoder = CatChannelConvDecoder(\n",
    "#     num_in=N, num_out=K, in_dim=split_conv_output_shape\n",
    "# )\n",
    "\n",
    "decoder = SparseMLPDecoder(num_in=N, num_out=K, in_dim=split_conv_output_shape)\n",
    "\n",
    "# encoder = CatBatchSizeConvEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "# decoder = CatBatchSizeConvDecoder(num_in=N, num_out=K, in_dim=split_conv_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总大小为：1.112MB\n",
      "模型总大小为：4.619MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getModelSize(model):\n",
    "    param_size = 0\n",
    "    param_sum = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "        param_sum += param.nelement()\n",
    "    buffer_size = 0\n",
    "    buffer_sum = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "        buffer_sum += buffer.nelement()\n",
    "    all_size = (param_size + buffer_size) / 1024 / 1024\n",
    "    print(\"模型总大小为：{:.3f}MB\".format(all_size))\n",
    "    return (param_size, param_sum, buffer_size, buffer_sum, all_size)\n",
    "\n",
    "getModelSize(encoder)\n",
    "getModelSize(decoder)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练 Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 5\n",
      "Train dataset: 60000\n",
      "image size:  torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|████████████████████| 938/938 [01:16<00:00, 12.22it/s, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.8941519260406494\n",
      "Train Accuracy: 31.238333333333333%\n",
      "Original Accuracy: 99.35333333333334%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|████████████████████| 938/938 [01:15<00:00, 12.39it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.0921862125396729\n",
      "Train Accuracy: 87.445%\n",
      "Original Accuracy: 99.35333333333334%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|████████████████████| 938/938 [01:16<00:00, 12.29it/s, loss=0.972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.9724389314651489\n",
      "Train Accuracy: 93.61666666666666%\n",
      "Original Accuracy: 99.35333333333334%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|████████████████████| 938/938 [01:17<00:00, 12.11it/s, loss=0.834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.8336547613143921\n",
      "Train Accuracy: 95.48833333333333%\n",
      "Original Accuracy: 99.35333333333334%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|████████████████████| 938/938 [01:17<00:00, 12.04it/s, loss=0.828]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.8275072574615479\n",
      "Train Accuracy: 96.66833333333334%\n",
      "Original Accuracy: 99.35333333333334%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 5  # ARG\n",
    "print(f\"epoch_num: {epoch_num}\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)}\")\n",
    "print(\"image size: \", train_dataset[0][0].size())\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer_encoder = optim.SGD(encoder.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
    "optimizer_decoder = optim.SGD(decoder.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "model.to(device)\n",
    "conv_segment.to(device)\n",
    "fc_segment.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "model.eval()\n",
    "conv_segment.eval()\n",
    "fc_segment.eval()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "model.eval()\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.track_running_stats = False\n",
    "\n",
    "loss_list = [[] for _ in range(epoch_num)]\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loader_tqdm = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch+1}/{epoch_num}\",\n",
    "        bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "    )\n",
    "    correct = 0\n",
    "    correct_truth = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader_tqdm:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # split image tensor(64, 3, 32, 32) -> [tensor(64, 3, 32, 8) * K]\n",
    "        images_list = []\n",
    "        for _1, _2, start, end in split_data_range:\n",
    "            images_list.append(images[:, :, :, start:end].clone())\n",
    "\n",
    "        pad = (0, 3, 0, 0)\n",
    "        images_list[-1] = F.pad(images_list[-1], pad, \"constant\", value=0)\n",
    "\n",
    "        ground_truth = conv_segment(images)\n",
    "        ground_truth = ground_truth.view(ground_truth.size(0), -1)\n",
    "\n",
    "        # forward\n",
    "        images_list += encoder(images_list)\n",
    "        output_list = []\n",
    "        for i in range(N):\n",
    "            output = conv_segment(images_list[i])\n",
    "            output_list.append(output)\n",
    "        # losed_output_list = lose_something(output_list, self.lose_device_index)\n",
    "        decoded_output_list = decoder(output_list)\n",
    "        output = torch.cat(decoded_output_list, dim=3)\n",
    "        output = output.view(output.size(0), -1)\n",
    "\n",
    "        loss = criterion(output, ground_truth)\n",
    "        # loss = criterion2(fc_segment(output), fc_segment(ground_truth))\n",
    "\n",
    "        loss_list[epoch].append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=10.0)\n",
    "        torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=10.0)\n",
    "        optimizer_encoder.step()\n",
    "        optimizer_decoder.step()\n",
    "\n",
    "        # calculate accuracy\n",
    "        _, predicted = torch.max(fc_segment(output).data, 1)\n",
    "        _, predicted_truth = torch.max(fc_segment(ground_truth.data), 1)\n",
    "        # print(predicted)\n",
    "        # print(predicted_truth)\n",
    "        # print(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        correct_truth += (predicted_truth == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "    print(f\"Train Accuracy: {100 * correct / total}%\")\n",
    "    print(f\"Original Accuracy: {100 * correct_truth / total}%\")\n",
    "    # 27%\n",
    "    # 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lose_something(output_list, lose_num):\n",
    "    if lose_num == 0:\n",
    "        return output_list\n",
    "    \n",
    "    lose_index = torch.randperm(len(output_list))[:lose_num]\n",
    "    losed_output_list = []\n",
    "\n",
    "    for i in range(len(output_list)):\n",
    "\n",
    "        if i in lose_index:\n",
    "\n",
    "            losed_output_list.append(torch.zeros_like(output_list[i]))\n",
    "        else:\n",
    "\n",
    "            losed_output_list.append(output_list[i])\n",
    "    return losed_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset.image_dataset import ImageDataset\n",
    "from util.split_data import split_vector\n",
    "\n",
    "conv_segment.to(device)\n",
    "fc_segment.to(device)\n",
    "model.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "conv_segment.eval()\n",
    "fc_segment.eval()\n",
    "model.eval()\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "def evaluation(loader, loss_num):\n",
    "    original_correct = 0\n",
    "    merge_correct = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        loader_tqdm = tqdm(\n",
    "            loader,\n",
    "            desc=f\"Evaluating...\",\n",
    "            bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "        )\n",
    "        for images, labels in loader_tqdm:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # split image tensor(64, 3, 32, 32) -> [tensor(64, 3, 32, 8) * K]\n",
    "            images_list = []\n",
    "            for _1, _2, start, end in split_data_range:\n",
    "                images_list.append(images[:, :, :, start:end].clone())\n",
    "        \n",
    "            pad = (0, 3, 0, 0)\n",
    "            images_list[-1] = F.pad(images_list[-1], pad, \"constant\", value=0)\n",
    "\n",
    "            _, predicted = torch.max(model(images).data, 1)\n",
    "            original_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            output = conv_segment(images)\n",
    "            output = output.view(output.size(0), -1)\n",
    "            output = fc_segment(output)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            merge_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            imageDataset_list = [\n",
    "                ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "            ]\n",
    "            output_list = []\n",
    "            for i in range(N):\n",
    "                imageDataset = imageDataset_list[i]\n",
    "                output = conv_segment(imageDataset.images)\n",
    "                output_list.append(output)\n",
    "            losed_output_list = lose_something(output_list, loss_num)\n",
    "            decoded_output_list = decoder(losed_output_list)\n",
    "            output = torch.cat(decoded_output_list, dim=3)\n",
    "            output = output.view(output.size(0), -1)\n",
    "\n",
    "            _, predicted = torch.max(fc_segment(output).data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"样本总数: {total}\")\n",
    "    print(\n",
    "        f\"原始模型(model) -> 预测正确数: {original_correct}, 预测准确率: {100 * original_correct / total}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"原始模型(conv+fc) -> 预测正确数: {merge_correct}, 预测准确率: {100 * merge_correct / total}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"使用Encoder和Decoder -> 预测正确数: {correct}, 预测准确率: {100 * correct / total}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练\n",
      "loss_num: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:27<00:00, 33.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "原始模型(conv+fc) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "使用Encoder和Decoder -> 预测正确数: 58233, 预测准确率: 97.055%\n",
      "loss_num: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:27<00:00, 34.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "原始模型(conv+fc) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "使用Encoder和Decoder -> 预测正确数: 57272, 预测准确率: 95.45333333333333%\n",
      "loss_num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:27<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "原始模型(conv+fc) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "使用Encoder和Decoder -> 预测正确数: 55178, 预测准确率: 91.96333333333334%\n",
      "loss_num: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:28<00:00, 33.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "原始模型(conv+fc) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "使用Encoder和Decoder -> 预测正确数: 51657, 预测准确率: 86.095%\n",
      "loss_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:28<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "原始模型(conv+fc) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "使用Encoder和Decoder -> 预测正确数: 43923, 预测准确率: 73.205%\n",
      "loss_num: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:27<00:00, 33.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "原始模型(conv+fc) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "使用Encoder和Decoder -> 预测正确数: 30391, 预测准确率: 50.651666666666664%\n",
      "loss_num: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:28<00:00, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "原始模型(conv+fc) -> 预测正确数: 59612, 预测准确率: 99.35333333333334%\n",
      "使用Encoder和Decoder -> 预测正确数: 6742, 预测准确率: 11.236666666666666%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "print(\"训练\")\n",
    "for i in range(N + 1):\n",
    "    print(f\"loss_num: {i}\")\n",
    "    evaluation(train_loader, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试\n",
      "loss_num: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:04<00:00, 33.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "原始模型(conv+fc) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "使用Encoder和Decoder -> 预测正确数: 9708, 预测准确率: 97.08%\n",
      "loss_num: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:04<00:00, 33.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "原始模型(conv+fc) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "使用Encoder和Decoder -> 预测正确数: 9540, 预测准确率: 95.4%\n",
      "loss_num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:04<00:00, 33.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "原始模型(conv+fc) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "使用Encoder和Decoder -> 预测正确数: 9315, 预测准确率: 93.15%\n",
      "loss_num: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:04<00:00, 33.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "原始模型(conv+fc) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "使用Encoder和Decoder -> 预测正确数: 8670, 预测准确率: 86.7%\n",
      "loss_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:04<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "原始模型(conv+fc) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "使用Encoder和Decoder -> 预测正确数: 7467, 预测准确率: 74.67%\n",
      "loss_num: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:04<00:00, 33.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "原始模型(conv+fc) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "使用Encoder和Decoder -> 预测正确数: 5679, 预测准确率: 56.79%\n",
      "loss_num: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:04<00:00, 33.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "原始模型(conv+fc) -> 预测正确数: 9891, 预测准确率: 98.91%\n",
      "使用Encoder和Decoder -> 预测正确数: 1135, 预测准确率: 11.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "print(\"测试\")\n",
    "for i in range(N + 1):\n",
    "    print(f\"loss_num: {i}\")\n",
    "    evaluation(test_loader, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
