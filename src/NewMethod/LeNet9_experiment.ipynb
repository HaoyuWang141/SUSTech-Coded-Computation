{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "original dir:  d:\\我的\\大学\\3春\\学业\\创新实践\\repo\\Nonlinear-Erasure-Code\\src\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"original dir: \", os.getcwd())\n",
    "\n",
    "if os.getcwd().endswith(\"NewMethod\"):\n",
    "    new_path = \"../\"\n",
    "    os.chdir(new_path)\n",
    "    print(\"changed dir: \", os.getcwd())\n",
    "    \n",
    "import torch\n",
    "import torch.nn\n",
    "from torch import optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "TASK_CONFIG = {\n",
    "    \"TASK\": \"CIFAR10\",  # ARGS\n",
    "    \"DATE\": datetime.datetime.now().strftime(\"%Y_%m_%d\"),\n",
    "    \"MODEL\": \"LeNet9\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前任务为 CIFAR10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置数据转换\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# 设置数据集（训练集与测试集合）\n",
    "\n",
    "\"\"\"\n",
    "MNIST:\n",
    "image: (1, 28, 28), label: (0-9)\n",
    "\n",
    "FashionMNIST:\n",
    "image: (1, 28, 28), label: (0-9)\n",
    "\n",
    "CIFAR10:\n",
    "image: (3, 32, 32), label: (0-9)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"当前任务为 {TASK_CONFIG['TASK']}\")\n",
    "\n",
    "# ARGS\n",
    "\n",
    "# train_dataset = datasets.MNIST(\n",
    "#     root=\"./data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_dataset = datasets.MNIST(\n",
    "#     root=\"./data\", train=False, download=True, transform=transform\n",
    "# )\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# train_dataset = datasets.FashionMNIST(\n",
    "#     root=\"./data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_dataset = datasets.FashionMNIST(\n",
    "#     root=\"./data\", train=False, download=True, transform=transform\n",
    "# )\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform,\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform,\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Data is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置部分参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 4\n",
      "R: 2\n",
      "N: 6\n",
      "data_shape: (3, 32, 32)\n",
      "num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "# ARGS\n",
    "K = 4\n",
    "R = 2\n",
    "N = K + R\n",
    "original_data_shape = tuple(train_dataset[0][0].shape)\n",
    "num_classes = 10\n",
    "print(f\"K: {K}\")\n",
    "print(f\"R: {R}\")\n",
    "print(f\"N: {N}\")\n",
    "print(f\"data_shape: {original_data_shape}\")\n",
    "print(f\"num_classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_input_size: 4096\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from base_model.MNIST_LeNet9 import LeNet9 as LeNet9_MNIST\n",
    "from base_model.Fashion_LeNet9 import LeNet9 as LeNet9_FashionMNIST\n",
    "from base_model.CIFAR10_LeNet9 import  LeNet9 as LeNet9_CIFAR10\n",
    "\n",
    "assert TASK_CONFIG[\"MODEL\"] == \"LeNet9\"\n",
    "\n",
    "if TASK_CONFIG[\"TASK\"] == \"MNIST\":\n",
    "    model = LeNet9_MNIST(input_dim=original_data_shape, num_classes=num_classes)\n",
    "elif TASK_CONFIG[\"TASK\"] == \"FashionMNIST\":\n",
    "    model = LeNet9_FashionMNIST(input_dim=original_data_shape, num_classes=num_classes)\n",
    "elif TASK_CONFIG[\"TASK\"] == \"CIFAR10\":\n",
    "    model = LeNet9_CIFAR10(input_dim=original_data_shape, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_path: ./base_model/LeNet9/CIFAR10/model.pth\n",
      "Model is ready!\n"
     ]
    }
   ],
   "source": [
    "# 读取模型\n",
    "base_model_path = (\n",
    "    f\"./base_model/{TASK_CONFIG['MODEL']}/{TASK_CONFIG['TASK']}/model.pth\"\n",
    ")\n",
    "print(f\"base_model_path: {base_model_path}\")\n",
    "\n",
    "model.load_state_dict(torch.load(base_model_path, map_location=device))\n",
    "conv_segment = model.get_conv_segment()\n",
    "fc_segment = model.get_fc_segment()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 base model 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集-> 总量: 50000, 正确数量: 43124, 准确率: 86.248%\n",
      "测试集-> 总量: 10000, 正确数量: 7432, 准确率: 74.32%\n"
     ]
    }
   ],
   "source": [
    "# 测试循环\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 在评估过程中不计算梯度\n",
    "    for data, target in train_loader:\n",
    "        # 将数据移动到设备上\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"训练集-> 总量: {total}, 正确数量: {correct}, 准确率: {100 * correct / total}%\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 在评估过程中不计算梯度\n",
    "    for data, target in test_loader:\n",
    "        # 将数据移动到设备上\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"测试集-> 总量: {total}, 正确数量: {correct}, 准确率: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 model 和 conv_segment, fc_segment 的输出是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2478, -0.2410, -3.1250, -3.4595, -3.4243, -6.0866, -1.6145, -5.7453,\n",
      "          3.9988, -0.6304]], device='cuda:0')\n",
      "tensor([[ 1.2478, -0.2410, -3.1250, -3.4595, -3.4243, -6.0866, -1.6145, -5.7453,\n",
      "          3.9988, -0.6304]], device='cuda:0')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, *original_data_shape).to(device)\n",
    "model.to(device)\n",
    "y = model(x)\n",
    "print(y.data)\n",
    "\n",
    "z = conv_segment(x)\n",
    "z = z.flatten(1)\n",
    "z = fc_segment(z)\n",
    "print(z.data)\n",
    "print(torch.allclose(y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置另一部分参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_output_shape: (256, 4, 4)\n",
      "split_conv_output_shape: (256, 4, 1)\n",
      "split_data_range: [(3, 32, 0, 23), (3, 32, 4, 27), (3, 32, 8, 31), (3, 32, 12, 32)]\n",
      "split_conv_output_data_shape from split_data_shape: [(1, 256, 4, 1), (1, 256, 4, 1), (1, 256, 4, 1), (1, 256, 4, 1)]\n",
      "split_data_shapes: [(3, 32, 23), (3, 32, 23), (3, 32, 23), (3, 32, 20)]\n",
      "choose the first one as the split_data_shape: (3, 32, 23)\n"
     ]
    }
   ],
   "source": [
    "from util.util import cal_input_shape\n",
    "\n",
    "\n",
    "conv_output_shape = model.calculate_conv_output(input_dim=original_data_shape)\n",
    "print(f\"conv_output_shape: {conv_output_shape}\")\n",
    "assert conv_output_shape[2] % K == 0\n",
    "\n",
    "split_conv_output_shape = (\n",
    "    conv_output_shape[0],\n",
    "    conv_output_shape[1],\n",
    "    conv_output_shape[2] // K,\n",
    ")\n",
    "print(f\"split_conv_output_shape: {split_conv_output_shape}\")\n",
    "\n",
    "conv_segment.to('cpu')\n",
    "conv_segment.train()\n",
    "split_data_range = cal_input_shape(\n",
    "    model=conv_segment,\n",
    "    original_input_shape=original_data_shape,\n",
    "    original_output_shape=conv_output_shape,\n",
    "    split_num=K,\n",
    ")\n",
    "print(f\"split_data_range: {split_data_range}\")\n",
    "\n",
    "# print(conv_segment)\n",
    "print(\n",
    "    f\"split_conv_output_data_shape from split_data_shape: {[tuple(conv_segment(torch.randn(1, _[0], _[1], _[3] - _[2])).shape) for _ in split_data_range]}\"\n",
    ")\n",
    "\n",
    "split_data_shapes = [\n",
    "    (\n",
    "        _[0],\n",
    "        _[1],\n",
    "        _[3] - _[2],\n",
    "    )\n",
    "    for _ in split_data_range\n",
    "]\n",
    "print(f\"split_data_shapes: {split_data_shapes}\")\n",
    "\n",
    "split_data_shape = split_data_shapes[0]\n",
    "print(f\"choose the first one as the split_data_shape: {split_data_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证分割后的输入，能够恰好恢复出原始输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape: torch.Size([1, 256, 4, 4])\n",
      "y_split.shape: [(1, 256, 4, 1), (1, 256, 4, 1), (1, 256, 4, 1), (1, 256, 4, 1)]\n",
      "y_hat.shape: torch.Size([1, 256, 4, 4])\n",
      "y和y_hat是否相等: False\n",
      "y和y_hat是否相等: False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, *original_data_shape).to(device)\n",
    "conv_segment.to(device)\n",
    "y = conv_segment(x)\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "\n",
    "x_split = [x[:, :, :, _[2]:_[3]] for _ in split_data_range]\n",
    "y_split = [conv_segment(_x) for _x in x_split]\n",
    "print(f\"y_split.shape: {[tuple(_y.shape) for _y in y_split]}\")\n",
    "\n",
    "y_hat = torch.cat(y_split, dim=3)\n",
    "print(f\"y_hat.shape: {y_hat.shape}\")\n",
    "\n",
    "# |A-B| <= atol + rtol * |B|\n",
    "print(f\"y和y_hat是否相等: {torch.allclose(y_hat, y, rtol=1e-08, atol=1e-05)}\")\n",
    "\n",
    "diff = torch.abs(y_hat - y)\n",
    "epsilon = 0.0001\n",
    "print(f\"y和y_hat是否相等: {torch.all(diff <= epsilon)}\")\n",
    "# print(torch.allclose(y_split[0], y[:, :, :, 0:5]))\n",
    "# print(torch.allclose(y_split[1], y[:, :, :, 5:10]))\n",
    "# print(torch.allclose(y_split[2], y[:, :, :, 10:15]))\n",
    "# print(torch.allclose(y_split[3], y[:, :, :, 15:20]))\n",
    "\n",
    "# print(y[0][0][0] == y_hat[0][0][0])\n",
    "# print(y[0][0][0])\n",
    "# print(y_hat[0][0][0])\n",
    "# y = x\n",
    "# y_split = x_split\n",
    "# for layer in conv_segment:\n",
    "#     print(layer)\n",
    "#     y = layer(y)\n",
    "#     y_split = [layer(_y) for _y in y_split]\n",
    "#     print(f\"y.shape: {y.shape}\")\n",
    "#     print(f\"y_split.shape: {[tuple(_.shape) for _ in y_split]}\")\n",
    "#     print(y[0][0][0])\n",
    "#     print(y_split[0][0][0][0])\n",
    "#     print(y_split[1][0][0][0])\n",
    "#     print(y_split[2][0][0][0])\n",
    "#     print(y_split[3][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_data_shape: (3, 32, 23)\n",
      "split_conv_output_shape: (256, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "from encoder.mlp_encoder import MLPEncoder\n",
    "# from encoder.conv_encoder import CatChannelConvEncoder, CatBatchSizeConvEncoder\n",
    "from encoder.CIFAR10_conv_encoder import CatChannelConvEncoder, CatBatchSizeConvEncoder\n",
    "from decoder.mlp_decoder import MLPDecoder\n",
    "from decoder.conv_decoder import CatChannelConvDecoder, CatBatchSizeConvDecoder\n",
    "\n",
    "print(f\"split_data_shape: {split_data_shape}\")\n",
    "print(f\"split_conv_output_shape: {split_conv_output_shape}\")\n",
    "\n",
    "# ARGS\n",
    "\n",
    "# encoder = MLPEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "decoder = MLPDecoder(num_in=N, num_out=K, in_dim=split_conv_output_shape)\n",
    "\n",
    "encoder = CatChannelConvEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "# decoder = CatChannelConvDecoder(\n",
    "#     num_in=N, num_out=K, in_dim=split_conv_output_shape\n",
    "# )\n",
    "\n",
    "# encoder = CatBatchSizeConvEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "# decoder = CatBatchSizeConvDecoder(num_in=N, num_out=K, in_dim=split_conv_output_data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总大小为：1.135MB\n",
      "模型总大小为：224.047MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getModelSize(model):\n",
    "    param_size = 0\n",
    "    param_sum = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "        param_sum += param.nelement()\n",
    "    buffer_size = 0\n",
    "    buffer_sum = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "        buffer_sum += buffer.nelement()\n",
    "    all_size = (param_size + buffer_size) / 1024 / 1024\n",
    "    print(\"模型总大小为：{:.3f}MB\".format(all_size))\n",
    "    return (param_size, param_sum, buffer_size, buffer_sum, all_size)\n",
    "\n",
    "getModelSize(encoder)\n",
    "getModelSize(decoder)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练 Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 10\n",
      "Train dataset: 50000\n",
      "image size:  torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████| 391/391 [04:43<00:00,  1.38it/s, loss=0.0125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 86.248%, Train Accuracy: 71.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████| 391/391 [04:42<00:00,  1.38it/s, loss=0.0068] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 86.248%, Train Accuracy: 82.128%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████████████| 391/391 [04:42<00:00,  1.38it/s, loss=0.00526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 86.248%, Train Accuracy: 83.492%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████| 391/391 [04:41<00:00,  1.39it/s, loss=0.0042] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 86.248%, Train Accuracy: 84.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████| 391/391 [04:42<00:00,  1.38it/s, loss=0.00391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 86.248%, Train Accuracy: 84.592%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████████████| 391/391 [04:42<00:00,  1.38it/s, loss=0.00306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 86.248%, Train Accuracy: 84.882%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████████████| 391/391 [04:42<00:00,  1.39it/s, loss=0.00261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 86.248%, Train Accuracy: 85.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   1%|▏                   | 4/391 [00:03<05:50,  1.10it/s, loss=0.00252]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 94\u001b[0m\n\u001b[0;32m     90\u001b[0m _, predicted_truth \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(fc_segment(ground_truth\u001b[38;5;241m.\u001b[39mdata), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# print(predicted)\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# print(predicted_truth)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# print(labels)\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m correct_truth \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted_truth \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     96\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 10  # ARGS\n",
    "print(f\"epoch_num: {epoch_num}\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)}\")\n",
    "print(\"image size: \", train_dataset[0][0].size())\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# optimizer_encoder = optim.SGD(encoder.parameters(), lr=1e-3, momentum=0.8, weight_decay=1e-5)\n",
    "# optimizer_decoder = optim.SGD(decoder.parameters(), lr=1e-3, momentum=0.8, weight_decay=1e-5)\n",
    "\n",
    "optimizer_encoder = optim.Adam(encoder.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "optimizer_decoder = optim.Adam(decoder.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "model.to(device)\n",
    "conv_segment.to(device)\n",
    "fc_segment.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "model.eval()\n",
    "conv_segment.eval()\n",
    "fc_segment.eval()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "model.eval()\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.track_running_stats = False\n",
    "\n",
    "loss_list = [[] for _ in range(epoch_num)]\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loader_tqdm = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch+1}/{epoch_num}\",\n",
    "        bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "    )\n",
    "    correct = 0\n",
    "    correct_truth = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader_tqdm:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # split image tensor(64, 3, 32, 32) -> [tensor(64, 3, 32, 8) * K]\n",
    "        images_list = []\n",
    "        for _1, _2, start, end in split_data_range:\n",
    "            images_list.append(images[:, :, :, start:end].clone())\n",
    "\n",
    "        pad = (0, 3, 0, 0)\n",
    "        images_list[-1] = F.pad(images_list[-1], pad, \"constant\", value=0)\n",
    "\n",
    "        ground_truth = conv_segment(images)\n",
    "        ground_truth = ground_truth.view(ground_truth.size(0), -1)\n",
    "\n",
    "        # forward\n",
    "        images_list += encoder(images_list)\n",
    "        output_list = []\n",
    "        for i in range(N):\n",
    "            output = conv_segment(images_list[i])\n",
    "            output_list.append(output)\n",
    "        # losed_output_list = lose_something(output_list, self.lose_device_index)\n",
    "        decoded_output_list = decoder(output_list)\n",
    "        output = torch.cat(decoded_output_list, dim=3)\n",
    "        output = output.view(output.size(0), -1)\n",
    "\n",
    "        loss = criterion(output, ground_truth)\n",
    "\n",
    "        loss_list[epoch].append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_encoder.step()\n",
    "        optimizer_decoder.step()\n",
    "\n",
    "        # calculate accuracy\n",
    "        _, predicted = torch.max(fc_segment(output).data, 1)\n",
    "        _, predicted_truth = torch.max(fc_segment(ground_truth.data), 1)\n",
    "        # print(predicted)\n",
    "        # print(predicted_truth)\n",
    "        # print(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        correct_truth += (predicted_truth == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Original Accuracy: {100 * correct_truth / total}%, Train Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lose_something(output_list, lose_num):\n",
    "    if lose_num == 0:\n",
    "        return output_list\n",
    "    \n",
    "    lose_index = torch.randperm(len(output_list))[:lose_num]\n",
    "    losed_output_list = []\n",
    "\n",
    "    for i in range(len(output_list)):\n",
    "\n",
    "        if i in lose_index:\n",
    "\n",
    "            losed_output_list.append(torch.zeros_like(output_list[i]))\n",
    "        else:\n",
    "\n",
    "            losed_output_list.append(output_list[i])\n",
    "    return losed_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset.image_dataset import ImageDataset\n",
    "from util.split_data import split_vector\n",
    "\n",
    "conv_segment.to(device)\n",
    "fc_segment.to(device)\n",
    "model.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "conv_segment.eval()\n",
    "fc_segment.eval()\n",
    "model.eval()\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "def evaluation(loader, loss_num):\n",
    "    original_correct = 0\n",
    "    merge_correct = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        loader_tqdm = tqdm(\n",
    "            loader,\n",
    "            desc=f\"Evaluating...\",\n",
    "            bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "        )\n",
    "        for images, labels in loader_tqdm:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # split image tensor(64, 3, 32, 32) -> [tensor(64, 3, 32, 8) * K]\n",
    "            images_list = []\n",
    "            for _1, _2, start, end in split_data_range:\n",
    "                images_list.append(images[:, :, :, start:end].clone())\n",
    "        \n",
    "            pad = (0, 3, 0, 0)\n",
    "            images_list[-1] = F.pad(images_list[-1], pad, \"constant\", value=0)\n",
    "\n",
    "            _, predicted = torch.max(model(images).data, 1)\n",
    "            original_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            output = conv_segment(images)\n",
    "            output = output.view(output.size(0), -1)\n",
    "            output = fc_segment(output)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            merge_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            imageDataset_list = [\n",
    "                ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "            ]\n",
    "            output_list = []\n",
    "            for i in range(N):\n",
    "                imageDataset = imageDataset_list[i]\n",
    "                output = conv_segment(imageDataset.images)\n",
    "                output_list.append(output)\n",
    "            losed_output_list = lose_something(output_list, loss_num)\n",
    "            decoded_output_list = decoder(losed_output_list)\n",
    "            output = torch.cat(decoded_output_list, dim=3)\n",
    "            output = output.view(output.size(0), -1)\n",
    "\n",
    "            _, predicted = torch.max(fc_segment(output).data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"样本总数: {total}\")\n",
    "    print(\n",
    "        f\"原始模型(model) -> 预测正确数: {original_correct}, 预测准确率: {(100 * original_correct / total):.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"原始模型(conv+fc) -> 预测正确数: {merge_correct}, 预测准确率: {(100 * merge_correct / total):.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"使用Encoder和Decoder -> 预测正确数: {correct}, 预测准确率: {(100 * correct / total):.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练\n",
      "loss_num: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 391/391 [01:36<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 50000\n",
      "原始模型(model) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "原始模型(conv+fc) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "使用Encoder和Decoder -> 预测正确数: 42581, 预测准确率: 85.16%\n",
      "loss_num: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 391/391 [01:35<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 50000\n",
      "原始模型(model) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "原始模型(conv+fc) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "使用Encoder和Decoder -> 预测正确数: 40322, 预测准确率: 80.64%\n",
      "loss_num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 391/391 [01:35<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 50000\n",
      "原始模型(model) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "原始模型(conv+fc) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "使用Encoder和Decoder -> 预测正确数: 36919, 预测准确率: 73.84%\n",
      "loss_num: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 391/391 [01:36<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 50000\n",
      "原始模型(model) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "原始模型(conv+fc) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "使用Encoder和Decoder -> 预测正确数: 33009, 预测准确率: 66.02%\n",
      "loss_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 391/391 [01:36<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 50000\n",
      "原始模型(model) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "原始模型(conv+fc) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "使用Encoder和Decoder -> 预测正确数: 27064, 预测准确率: 54.13%\n",
      "loss_num: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 391/391 [01:35<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 50000\n",
      "原始模型(model) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "原始模型(conv+fc) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "使用Encoder和Decoder -> 预测正确数: 18440, 预测准确率: 36.88%\n",
      "loss_num: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 391/391 [01:35<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 50000\n",
      "原始模型(model) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "原始模型(conv+fc) -> 预测正确数: 43124, 预测准确率: 86.25%\n",
      "使用Encoder和Decoder -> 预测正确数: 5000, 预测准确率: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "print(\"训练\")\n",
    "for i in range(N + 1):\n",
    "    print(f\"loss_num: {i}\")\n",
    "    evaluation(train_loader, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试\n",
      "loss_num: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:20<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "原始模型(conv+fc) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "使用Encoder和Decoder -> 预测正确数: 7436, 预测准确率: 74.36%\n",
      "loss_num: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:20<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "原始模型(conv+fc) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "使用Encoder和Decoder -> 预测正确数: 7152, 预测准确率: 71.52%\n",
      "loss_num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:20<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "原始模型(conv+fc) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "使用Encoder和Decoder -> 预测正确数: 6662, 预测准确率: 66.62%\n",
      "loss_num: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:20<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "原始模型(conv+fc) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "使用Encoder和Decoder -> 预测正确数: 6119, 预测准确率: 61.19%\n",
      "loss_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:20<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "原始模型(conv+fc) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "使用Encoder和Decoder -> 预测正确数: 5145, 预测准确率: 51.45%\n",
      "loss_num: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:20<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "原始模型(conv+fc) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "使用Encoder和Decoder -> 预测正确数: 3514, 预测准确率: 35.14%\n",
      "loss_num: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:20<00:00,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "原始模型(conv+fc) -> 预测正确数: 7432, 预测准确率: 74.32%\n",
      "使用Encoder和Decoder -> 预测正确数: 1000, 预测准确率: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "print(\"测试\")\n",
    "for i in range(N + 1):\n",
    "    print(f\"loss_num: {i}\")\n",
    "    evaluation(test_loader, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
