{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "original dir:  d:\\我的\\大学\\3春\\学业\\创新实践\\repo\\Nonlinear-Erasure-Code\\src\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"original dir: \", os.getcwd())\n",
    "\n",
    "if os.getcwd().endswith(\"NewMethod\"):\n",
    "    new_path = \"../\"\n",
    "    os.chdir(new_path)\n",
    "    print(\"changed dir: \", os.getcwd())\n",
    "    \n",
    "import torch\n",
    "import torch.nn\n",
    "from torch import optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "TASK_CONFIG = {\n",
    "    \"TASK\": \"FashionMNIST\",  # ARGS\n",
    "    \"DATE\": datetime.datetime.now().strftime(\"%Y_%m_%d\"),\n",
    "    \"MODEL\": \"LeNet9\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前任务为 FashionMNIST\n",
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置数据转换\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "# 设置数据集（训练集与测试集合）\n",
    "\n",
    "\"\"\"\n",
    "MNIST:\n",
    "image: (1, 28, 28), label: (0-9)\n",
    "\n",
    "FashionMNIST:\n",
    "image: (1, 28, 28), label: (0-9)\n",
    "\n",
    "CIFAR10:\n",
    "image: (3, 32, 32), label: (0-9)\n",
    "\"\"\"\n",
    "\n",
    "print(f\"当前任务为 {TASK_CONFIG['TASK']}\")\n",
    "\n",
    "# ARGS\n",
    "\n",
    "# train_dataset = datasets.MNIST(\n",
    "#     root=\"./data\", train=True, download=True, transform=transform\n",
    "# )\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_dataset = datasets.MNIST(\n",
    "#     root=\"./data\", train=False, download=True, transform=transform\n",
    "# )\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# train_dataset = datasets.CIFAR10(\n",
    "#     root=\"./data\", train=True, download=True, transform=transform,\n",
    "# )\n",
    "# test_dataset = datasets.CIFAR10(\n",
    "#     root=\"./data\", train=False, download=True, transform=transform,\n",
    "# )\n",
    "# train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Data is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置部分参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 4\n",
      "R: 2\n",
      "N: 6\n",
      "data_shape: (1, 28, 28)\n",
      "num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "# ARGS\n",
    "K = 4\n",
    "R = 2\n",
    "N = K + R\n",
    "original_data_shape = tuple(train_dataset[0][0].shape)\n",
    "num_classes = 10\n",
    "print(f\"K: {K}\")\n",
    "print(f\"R: {R}\")\n",
    "print(f\"N: {N}\")\n",
    "print(f\"data_shape: {original_data_shape}\")\n",
    "print(f\"num_classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_input_size: 8192\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# from base_model.MNIST_LeNet9 import LeNet9\n",
    "from base_model.Fashion_LeNet9 import LeNet9\n",
    "\n",
    "# 引入 base model, 该model将在后续全部过程中使用\n",
    "# ResNet\n",
    "assert TASK_CONFIG[\"MODEL\"] == \"LeNet9\"\n",
    "model = LeNet9(input_dim=original_data_shape, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_path: ./base_model/LeNet9/FashionMNIST/model.pth\n",
      "Model is ready!\n"
     ]
    }
   ],
   "source": [
    "# 读取模型\n",
    "base_model_path = (\n",
    "    f\"./base_model/{TASK_CONFIG['MODEL']}/{TASK_CONFIG['TASK']}/model.pth\"\n",
    ")\n",
    "print(f\"base_model_path: {base_model_path}\")\n",
    "\n",
    "model.load_state_dict(torch.load(base_model_path, map_location=device))\n",
    "conv_segment = model.get_conv_segment()\n",
    "fc_segment = model.get_fc_segment()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 base model 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集-> 总量: 60000, 正确数量: 59139, 准确率: 98.565%\n",
      "测试集-> 总量: 10000, 正确数量: 9616, 准确率: 96.16%\n"
     ]
    }
   ],
   "source": [
    "# 测试循环\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 在评估过程中不计算梯度\n",
    "    for data, target in train_loader:\n",
    "        # 将数据移动到设备上\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"训练集-> 总量: {total}, 正确数量: {correct}, 准确率: {100 * correct / total}%\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 在评估过程中不计算梯度\n",
    "    for data, target in test_loader:\n",
    "        # 将数据移动到设备上\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"测试集-> 总量: {total}, 正确数量: {correct}, 准确率: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 model 和 conv_segment, fc_segment 的输出是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.2019, -0.7701, -2.0310, -5.0615, -1.5275,  5.1348,  0.8285, -3.5201,\n",
      "          6.8572, -2.3974]], device='cuda:0')\n",
      "tensor([[ 3.2019, -0.7701, -2.0310, -5.0615, -1.5275,  5.1348,  0.8285, -3.5201,\n",
      "          6.8572, -2.3974]], device='cuda:0')\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, *original_data_shape).to(device)\n",
    "model.to(device)\n",
    "y = model(x)\n",
    "print(y.data)\n",
    "\n",
    "z = conv_segment(x)\n",
    "z = z.flatten(1)\n",
    "z = fc_segment(z)\n",
    "print(z.data)\n",
    "print(torch.allclose(y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置另一部分参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_output_shape: (128, 8, 8)\n",
      "split_conv_output_shape: (128, 8, 2)\n",
      "split_data_range: [(1, 28, 0, 17), (1, 28, 4, 21), (1, 28, 8, 25), (1, 28, 12, 28)]\n",
      "split_conv_output_data_shape from split_data_shape: [(1, 128, 8, 2), (1, 128, 8, 2), (1, 128, 8, 2), (1, 128, 8, 2)]\n",
      "split_data_shapes: [(1, 28, 17), (1, 28, 17), (1, 28, 17), (1, 28, 16)]\n",
      "choose the first one as the split_data_shape: (1, 28, 17)\n"
     ]
    }
   ],
   "source": [
    "from util.util import cal_input_shape\n",
    "\n",
    "\n",
    "conv_output_shape = model.calculate_conv_output(input_dim=original_data_shape)\n",
    "print(f\"conv_output_shape: {conv_output_shape}\")\n",
    "assert conv_output_shape[2] % K == 0\n",
    "\n",
    "split_conv_output_shape = (\n",
    "    conv_output_shape[0],\n",
    "    conv_output_shape[1],\n",
    "    conv_output_shape[2] // K,\n",
    ")\n",
    "print(f\"split_conv_output_shape: {split_conv_output_shape}\")\n",
    "\n",
    "conv_segment.to('cpu')\n",
    "conv_segment.train()\n",
    "split_data_range = cal_input_shape(\n",
    "    model=conv_segment,\n",
    "    original_input_shape=original_data_shape,\n",
    "    original_output_shape=conv_output_shape,\n",
    "    split_num=K,\n",
    ")\n",
    "print(f\"split_data_range: {split_data_range}\")\n",
    "\n",
    "# print(conv_segment)\n",
    "print(\n",
    "    f\"split_conv_output_data_shape from split_data_shape: {[tuple(conv_segment(torch.randn(1, _[0], _[1], _[3] - _[2])).shape) for _ in split_data_range]}\"\n",
    ")\n",
    "\n",
    "split_data_shapes = [\n",
    "    (\n",
    "        _[0],\n",
    "        _[1],\n",
    "        _[3] - _[2],\n",
    "    )\n",
    "    for _ in split_data_range\n",
    "]\n",
    "print(f\"split_data_shapes: {split_data_shapes}\")\n",
    "\n",
    "split_data_shape = split_data_shapes[0]\n",
    "print(f\"choose the first one as the split_data_shape: {split_data_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证分割后的输入，能够恰好恢复出原始输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape: torch.Size([1, 128, 8, 8])\n",
      "y_split.shape: [(1, 128, 8, 2), (1, 128, 8, 2), (1, 128, 8, 2), (1, 128, 8, 2)]\n",
      "y_hat.shape: torch.Size([1, 128, 8, 8])\n",
      "y和y_hat是否相等: False\n",
      "y和y_hat是否相等: False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, *original_data_shape).to(device)\n",
    "conv_segment.to(device)\n",
    "y = conv_segment(x)\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "\n",
    "x_split = [x[:, :, :, _[2]:_[3]] for _ in split_data_range]\n",
    "y_split = [conv_segment(_x) for _x in x_split]\n",
    "print(f\"y_split.shape: {[tuple(_y.shape) for _y in y_split]}\")\n",
    "\n",
    "y_hat = torch.cat(y_split, dim=3)\n",
    "print(f\"y_hat.shape: {y_hat.shape}\")\n",
    "\n",
    "# |A-B| <= atol + rtol * |B|\n",
    "print(f\"y和y_hat是否相等: {torch.allclose(y_hat, y, rtol=1e-08, atol=1e-05)}\")\n",
    "\n",
    "diff = torch.abs(y_hat - y)\n",
    "epsilon = 0.0001\n",
    "print(f\"y和y_hat是否相等: {torch.all(diff <= epsilon)}\")\n",
    "# print(torch.allclose(y_split[0], y[:, :, :, 0:5]))\n",
    "# print(torch.allclose(y_split[1], y[:, :, :, 5:10]))\n",
    "# print(torch.allclose(y_split[2], y[:, :, :, 10:15]))\n",
    "# print(torch.allclose(y_split[3], y[:, :, :, 15:20]))\n",
    "\n",
    "# print(y[0][0][0] == y_hat[0][0][0])\n",
    "# print(y[0][0][0])\n",
    "# print(y_hat[0][0][0])\n",
    "# y = x\n",
    "# y_split = x_split\n",
    "# for layer in conv_segment:\n",
    "#     print(layer)\n",
    "#     y = layer(y)\n",
    "#     y_split = [layer(_y) for _y in y_split]\n",
    "#     print(f\"y.shape: {y.shape}\")\n",
    "#     print(f\"y_split.shape: {[tuple(_.shape) for _ in y_split]}\")\n",
    "#     print(y[0][0][0])\n",
    "#     print(y_split[0][0][0][0])\n",
    "#     print(y_split[1][0][0][0])\n",
    "#     print(y_split[2][0][0][0])\n",
    "#     print(y_split[3][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_data_shape: (1, 28, 17)\n",
      "split_conv_output_shape: (128, 8, 2)\n"
     ]
    }
   ],
   "source": [
    "from encoder.mlp_encoder import MLPEncoder\n",
    "from encoder.conv_encoder import CatChannelConvEncoder, CatBatchSizeConvEncoder\n",
    "from decoder.mlp_decoder import MLPDecoder\n",
    "from decoder.conv_decoder import CatChannelConvDecoder, CatBatchSizeConvDecoder\n",
    "\n",
    "print(f\"split_data_shape: {split_data_shape}\")\n",
    "print(f\"split_conv_output_shape: {split_conv_output_shape}\")\n",
    "\n",
    "# ARGS\n",
    "\n",
    "# encoder = MLPEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "# decoder = MLPDecoder(num_in=N, num_out=K, in_dim=split_conv_output_shape)\n",
    "\n",
    "encoder = CatChannelConvEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "decoder = CatChannelConvDecoder(\n",
    "    num_in=N, num_out=K, in_dim=split_conv_output_shape\n",
    ")\n",
    "\n",
    "# encoder = CatBatchSizeConvEncoder(num_in=K, num_out=R, in_dim=split_data_shape)\n",
    "# decoder = CatBatchSizeConvDecoder(num_in=N, num_out=K, in_dim=split_conv_output_data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总大小为：1.112MB\n",
      "模型总大小为：5.875MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getModelSize(model):\n",
    "    param_size = 0\n",
    "    param_sum = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "        param_sum += param.nelement()\n",
    "    buffer_size = 0\n",
    "    buffer_sum = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "        buffer_sum += buffer.nelement()\n",
    "    all_size = (param_size + buffer_size) / 1024 / 1024\n",
    "    print(\"模型总大小为：{:.3f}MB\".format(all_size))\n",
    "    return (param_size, param_sum, buffer_size, buffer_sum, all_size)\n",
    "\n",
    "getModelSize(encoder)\n",
    "getModelSize(decoder)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练 Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num: 15\n",
      "Train dataset: 60000\n",
      "image size:  torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|████████████████████| 938/938 [02:13<00:00,  7.00it/s, loss=1.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 49.745%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.97it/s, loss=0.865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 84.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.96it/s, loss=0.674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 88.92666666666666%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.95it/s, loss=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 90.73833333333333%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|████████████████████| 938/938 [02:19<00:00,  6.73it/s, loss=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 91.94166666666666%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|████████████████████| 938/938 [02:15<00:00,  6.95it/s, loss=0.533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 92.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.95it/s, loss=0.561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 93.33666666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.96it/s, loss=0.483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 93.71666666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.98it/s, loss=0.481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 94.145%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|████████████████████| 938/938 [02:13<00:00,  7.01it/s, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 94.35666666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|████████████████████| 938/938 [02:13<00:00,  7.01it/s, loss=0.421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 94.59333333333333%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.99it/s, loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 94.84166666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|████████████████████| 938/938 [02:13<00:00,  7.02it/s, loss=0.356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 95.02666666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|████████████████████| 938/938 [02:14<00:00,  6.99it/s, loss=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 95.20333333333333%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|████████████████████| 938/938 [02:13<00:00,  7.02it/s, loss=0.405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 98.565%, Train Accuracy: 95.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 15  # ARGS\n",
    "print(f\"epoch_num: {epoch_num}\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)}\")\n",
    "print(\"image size: \", train_dataset[0][0].size())\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# optimizer_encoder = optim.SGD(encoder.parameters(), lr=1e-3, momentum=0.8, weight_decay=1e-5)\n",
    "# optimizer_decoder = optim.SGD(decoder.parameters(), lr=1e-3, momentum=0.8, weight_decay=1e-5)\n",
    "\n",
    "optimizer_encoder = optim.Adam(encoder.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "optimizer_decoder = optim.Adam(decoder.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "model.to(device)\n",
    "conv_segment.to(device)\n",
    "fc_segment.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "model.eval()\n",
    "conv_segment.eval()\n",
    "fc_segment.eval()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "model.eval()\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.track_running_stats = False\n",
    "\n",
    "loss_list = [[] for _ in range(epoch_num)]\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loader_tqdm = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch+1}/{epoch_num}\",\n",
    "        bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "    )\n",
    "    correct = 0\n",
    "    correct_truth = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader_tqdm:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # split image tensor(64, 3, 32, 32) -> [tensor(64, 3, 32, 8) * K]\n",
    "        images_list = []\n",
    "        for _1, _2, start, end in split_data_range:\n",
    "            images_list.append(images[:, :, :, start:end].clone())\n",
    "\n",
    "        pad = (0, 1, 0, 0)\n",
    "        images_list[-1] = F.pad(images_list[-1], pad, \"constant\", value=0)\n",
    "\n",
    "        ground_truth = conv_segment(images)\n",
    "        ground_truth = ground_truth.view(ground_truth.size(0), -1)\n",
    "\n",
    "        # forward\n",
    "        images_list += encoder(images_list)\n",
    "        output_list = []\n",
    "        for i in range(N):\n",
    "            output = conv_segment(images_list[i])\n",
    "            output_list.append(output)\n",
    "        # losed_output_list = lose_something(output_list, self.lose_device_index)\n",
    "        decoded_output_list = decoder(output_list)\n",
    "        output = torch.cat(decoded_output_list, dim=3)\n",
    "        output = output.view(output.size(0), -1)\n",
    "\n",
    "        loss = criterion(output, ground_truth)\n",
    "\n",
    "        loss_list[epoch].append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_encoder.step()\n",
    "        optimizer_decoder.step()\n",
    "\n",
    "        # calculate accuracy\n",
    "        _, predicted = torch.max(fc_segment(output).data, 1)\n",
    "        _, predicted_truth = torch.max(fc_segment(ground_truth.data), 1)\n",
    "        # print(predicted)\n",
    "        # print(predicted_truth)\n",
    "        # print(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        correct_truth += (predicted_truth == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Original Accuracy: {100 * correct_truth / total}%, Train Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lose_something(output_list, lose_num):\n",
    "    if lose_num == 0:\n",
    "        return output_list\n",
    "    \n",
    "    lose_index = torch.randperm(len(output_list))[:lose_num]\n",
    "    losed_output_list = []\n",
    "\n",
    "    for i in range(len(output_list)):\n",
    "\n",
    "        if i in lose_index:\n",
    "\n",
    "            losed_output_list.append(torch.zeros_like(output_list[i]))\n",
    "        else:\n",
    "\n",
    "            losed_output_list.append(output_list[i])\n",
    "    return losed_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset.image_dataset import ImageDataset\n",
    "from util.split_data import split_vector\n",
    "\n",
    "conv_segment.to(device)\n",
    "fc_segment.to(device)\n",
    "model.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "conv_segment.eval()\n",
    "fc_segment.eval()\n",
    "model.eval()\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "def evaluation(loader, loss_num):\n",
    "    original_correct = 0\n",
    "    merge_correct = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        loader_tqdm = tqdm(\n",
    "            loader,\n",
    "            desc=f\"Evaluating...\",\n",
    "            bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "        )\n",
    "        for images, labels in loader_tqdm:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # split image tensor(64, 3, 32, 32) -> [tensor(64, 3, 32, 8) * K]\n",
    "            images_list = []\n",
    "            for _1, _2, start, end in split_data_range:\n",
    "                images_list.append(images[:, :, :, start:end].clone())\n",
    "        \n",
    "            pad = (0, 1, 0, 0)\n",
    "            images_list[-1] = F.pad(images_list[-1], pad, \"constant\", value=0)\n",
    "\n",
    "            _, predicted = torch.max(model(images).data, 1)\n",
    "            original_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            output = conv_segment(images)\n",
    "            output = output.view(output.size(0), -1)\n",
    "            output = fc_segment(output)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            merge_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            imageDataset_list = [\n",
    "                ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "            ]\n",
    "            output_list = []\n",
    "            for i in range(N):\n",
    "                imageDataset = imageDataset_list[i]\n",
    "                output = conv_segment(imageDataset.images)\n",
    "                output_list.append(output)\n",
    "            losed_output_list = lose_something(output_list, loss_num)\n",
    "            decoded_output_list = decoder(losed_output_list)\n",
    "            output = torch.cat(decoded_output_list, dim=3)\n",
    "            output = output.view(output.size(0), -1)\n",
    "\n",
    "            _, predicted = torch.max(fc_segment(output).data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"样本总数: {total}\")\n",
    "    print(\n",
    "        f\"原始模型(model) -> 预测正确数: {original_correct}, 预测准确率: {(100 * original_correct / total):.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"原始模型(conv+fc) -> 预测正确数: {merge_correct}, 预测准确率: {(100 * merge_correct / total):.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"使用Encoder和Decoder -> 预测正确数: {correct}, 预测准确率: {(100 * correct / total):.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练\n",
      "loss_num: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:43<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "原始模型(conv+fc) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "使用Encoder和Decoder -> 预测正确数: 57242, 预测准确率: 95.40%\n",
      "loss_num: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:43<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "原始模型(conv+fc) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "使用Encoder和Decoder -> 预测正确数: 54167, 预测准确率: 90.28%\n",
      "loss_num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:43<00:00, 21.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "原始模型(conv+fc) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "使用Encoder和Decoder -> 预测正确数: 49960, 预测准确率: 83.27%\n",
      "loss_num: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:43<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "原始模型(conv+fc) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "使用Encoder和Decoder -> 预测正确数: 43094, 预测准确率: 71.82%\n",
      "loss_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:43<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "原始模型(conv+fc) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "使用Encoder和Decoder -> 预测正确数: 33441, 预测准确率: 55.73%\n",
      "loss_num: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:43<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "原始模型(conv+fc) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "使用Encoder和Decoder -> 预测正确数: 19478, 预测准确率: 32.46%\n",
      "loss_num: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 938/938 [00:45<00:00, 20.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 60000\n",
      "原始模型(model) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "原始模型(conv+fc) -> 预测正确数: 59139, 预测准确率: 98.56%\n",
      "使用Encoder和Decoder -> 预测正确数: 6000, 预测准确率: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "print(\"训练\")\n",
    "for i in range(N + 1):\n",
    "    print(f\"loss_num: {i}\")\n",
    "    evaluation(train_loader, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试\n",
      "loss_num: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:07<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "原始模型(conv+fc) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "使用Encoder和Decoder -> 预测正确数: 9307, 预测准确率: 93.07%\n",
      "loss_num: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:07<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "原始模型(conv+fc) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "使用Encoder和Decoder -> 预测正确数: 8839, 预测准确率: 88.39%\n",
      "loss_num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:07<00:00, 21.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "原始模型(conv+fc) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "使用Encoder和Decoder -> 预测正确数: 8315, 预测准确率: 83.15%\n",
      "loss_num: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:07<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "原始模型(conv+fc) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "使用Encoder和Decoder -> 预测正确数: 7081, 预测准确率: 70.81%\n",
      "loss_num: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:07<00:00, 21.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "原始模型(conv+fc) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "使用Encoder和Decoder -> 预测正确数: 5475, 预测准确率: 54.75%\n",
      "loss_num: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:07<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "原始模型(conv+fc) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "使用Encoder和Decoder -> 预测正确数: 3005, 预测准确率: 30.05%\n",
      "loss_num: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|████████████████████| 157/157 [00:07<00:00, 21.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数: 10000\n",
      "原始模型(model) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "原始模型(conv+fc) -> 预测正确数: 9616, 预测准确率: 96.16%\n",
      "使用Encoder和Decoder -> 预测正确数: 1000, 预测准确率: 10.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "print(\"测试\")\n",
    "for i in range(N + 1):\n",
    "    print(f\"loss_num: {i}\")\n",
    "    evaluation(test_loader, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
